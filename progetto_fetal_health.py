# -*- coding: utf-8 -*-
"""progetto_fetal_health.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XT1rwNZx9QFmbIF2061LOuxRhEXYEjlC

# Importing data e libraries
"""

import pandas as pd
import numpy as np
import sklearn
from sklearn.preprocessing import StandardScaler
# Data visualization
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sea

from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/ML_Project

#Load dataset and reading it
data = 'fetal_health.csv'
df = pd.read_csv(data)
print(df.head())

df.shape

# Visualizing dataset info
pd.set_option('display.max_columns', None)
print(df.info())

df.describe()

df.columns.tolist()

#Checking for missing values
df.isnull().sum()

#Checking for duplicate values
df.nunique()

"""histogram_tendency e severe_decelerations hanno solo tre valori unici.
Da controllare.
"""

#Class distribution
print(df["fetal_health"].value_counts())
plt.figure()
figure = (df['fetal_health'].value_counts()*100.0/len(df)).plot.pie(autopct='%.1f%%', labels = ['Normal','Suspect','Pathological'])
plt.show()

#Summary statistic in numerical variables
print("\n\n\n Summary statistic in numerical variables")
print(round(df.describe(),6))
print(df.nunique())

fetal_health_counts = df['fetal_health'].value_counts()
print(fetal_health_counts)

#Count plot
plt.figure(figsize=(8,5))
plt.bar(fetal_health_counts.index, fetal_health_counts, color='skyblue')
plt.xlabel('Fetal Health')
plt.ylabel('Count')
plt.title('Fetal Health Distribution')
plt.show()

"""# Features selection

## Plotting features
"""

features = list(df.columns)
features.remove('fetal_health')
print(features)

sea.set_style("darkgrid")

#Skewness
plt.figure(figsize=(20,40))
i = 1
for f in features:
    plt.subplot(11,2,i)
    sea.histplot(data=df[f],label=f,fill=True,kde=True)
    plt.title(f"{f} | Skewness: {round(df[f].skew(),2)}")
    i+=1

# Adjust layout and show plots
plt.tight_layout()
plt.show()

plt.figure(figsize=(15,40))

i=1
for f in features:
    plt.subplot(11,2,i)
    fig = sea.boxplot(x='fetal_health', y=f, data=df)
    fig.set_title('')
    fig.set_ylabel(f)
    i+=1

plt.tight_layout()
plt.show()

plt.figure(figsize=(20,40))

i=1
for f in features:
  plt.subplot(11,2,i)
  df.boxplot(column=f)
  fig.set_title('')
  fig.set_ylabel(f)
  i+=1

fetal_health_ = ['Normal','Suspect','Pathological']
plt.figure(figsize=(20,40))
j = 1
for f in features:
    plt.subplot(11,2,j)
    #For each feature compare it with the three labels
    for i in range(3):
      sea.kdeplot(data=df[df['fetal_health']==i+1][f],label=fetal_health_[i],fill=True)
    plt.legend()
    j+=1

# Severe deceleratiion da un errore di varianza. Difatti assume solo due singoli valori su tutto il dataset. Si è deciso comunque di tenerla e valutare successivamente
# se rimuoverla

plt.figure(figsize=(50,40))
sea.heatmap(df.corr(),annot=True)
plt.show()

correlation = df.corr()
num_feature = correlation["fetal_health"].sort_values(ascending=False).head(20).to_frame()
style = num_feature.style.background_gradient()
style

"""## Selecting between histogram mode, median e mean"""

# histogram_mode, histogram_median e histogram_mean sono molto correllati fra loro.
# Essi rappresentano moda, mediana e media degli istogrammi relativi alla FHR (Fetal Heart Rate).

hist_features = ['histogram_mode', 'histogram_median', 'histogram_mean']
j = 1
for f in hist_features:
    plt.figure(figsize=(40,5))
    for i in range(3):
      plt.subplot(1,3,j)
      y = df[df["fetal_health"]==i+1][f]
      sea.kdeplot(data=y,label=fetal_health_[i],fill=True)
      plt.legend()
    j += 1

print("Di seguito con la correlazione con fetal_healt di: \n")
print("histogram_mode:", df['fetal_health'].corr(df['histogram_mode']))
print("histogram_median:", df['fetal_health'].corr(df['histogram_median']))
print("histogram_mean:", df['fetal_health'].corr(df['histogram_mean']))

"""**Le features più correlate erano la media e la mediana. Dai grafici precedenti si nota come difatti esse dividano le classi pressocchè nello stesso modo.
Si è deciso quindi di eliminare la feature meno correlata con l'output, ovvero la mediana (-0.21). Inoltre, è possibile notare come la moda si estenda di più a sinistra rispetto a media e mediana per i casi patologici (di maggiore interesse). Risulterà quindi una feature più discriminante per questa classe.**
"""

df = df.drop(columns='histogram_median')

features.remove('histogram_median')
print(features)

"""## histogram_min e histogram_width analysis"""

min_width = ['histogram_min', 'histogram_width']
j = 1
for f in min_width:
    plt.figure(figsize=(40,5))
    for i in range(3):
      plt.subplot(1,3,j)
      y = df[df["fetal_health"]==i+1][f]
      sea.kdeplot(data=y,label=fetal_health_[i],fill=True)
      plt.legend()
    j += 1

"""Le due features presentano un elevata correlazione ma presentano una correlazione molto diversa con l'output. Si decide quindi di lasciarle.

# Normalization e training
"""

X = df.drop(columns='fetal_health')
t = df['fetal_health']

print(df.columns)

# NON FARE L'OVERSAMPLING SUI DATI DEL TEST, da correggere. Più o meno fatto
# Split X and t into training and testing sets
from sklearn.model_selection import train_test_split
X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.3, random_state=0)

# Check the shape of X_train and X_test
print(X_train.shape)
print(X_test.shape)

# Oversampling of minority class
from imblearn.over_sampling import RandomOverSampler
oversample = RandomOverSampler(sampling_strategy='not majority')
X_train, t_train = oversample.fit_resample(X_train, t_train)

# from imblearn.over_sampling import SMOTE
# smote = SMOTE(sampling_strategy='not majority')
# X_train, t_train = smote.fit_resample(X_train, t_train)

# Normalization
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Check if data is normalized
print(X_train.mean(axis=0))
print(X_train.std(axis=0))

print(features)

plt.figure(figsize=(20,10))
sea.boxenplot(data=X_train)
fig.set_title('Normalized features')
#Rotating the features' name by 90 degree and exchanging the feature column with her name
plt.xticks(ticks=np.arange(len(features)),rotation=90,labels=features)

"""## Training

### Logistic Regression
"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, make_scorer

#Inizialize the softmax regression model
softmax_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=1, max_iter=1000)
grid = {"C": np.logspace(-3, 10, 7)}
# Perform grid search cross-validation with f1 as the scoring metric
f1 = make_scorer(f1_score, average='weighted')
softmax_reg_cv = GridSearchCV(softmax_reg, grid, cv=5, scoring=f1)
softmax_reg_cv.fit(X_train, t_train)

# Print the best parameters and accuracy from the grid search
print("Tuned hyperparameters (best parameters): ", softmax_reg_cv.best_params_)
print("F1: ", softmax_reg_cv.best_score_)

#Refine the parameter search
softmax_reg_ref = LogisticRegression(multi_class='multinomial', solver='lbfgs', C=1, max_iter=1000)
grid_ref = {"C": np.linspace(0.5, 1, 20)}
softmax_reg_ref.fit(X_train, t_train)
# Perform grid search cross-validation with f1 as the scoring metric
f1 = make_scorer(f1_score, average='weighted')
softmax_reg_cv_ref = GridSearchCV(softmax_reg_ref, grid_ref, cv=5, scoring=f1)
softmax_reg_cv_ref.fit(X_train, t_train)

# Print the best parameters and accuracy from the grid search
print("Tuned hyperparameters (best parameters): ", softmax_reg_cv_ref.best_params_)
print("F1: ", softmax_reg_cv_ref.best_score_)

Y_hat_test = softmax_reg_cv_ref.predict(X_test)
print("Accuracy score on the test set: ", accuracy_score(t_test, Y_hat_test))
print("F1 score on the test set: ", f1_score(t_test, Y_hat_test, average='weighted'))

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(t_test, Y_hat_test, labels=[1, 2, 3])
cm_matrix = pd.DataFrame(data=cm, columns=['Normal', 'Suspect', 'Pathological'], index=['Normal', 'Suspect', 'Pathological'])
sea.heatmap(cm_matrix, annot=True, fmt='d',cmap='YlGnBu')
print(cm)

"""### SVM"""

#importing SVC classifier
from sklearn.svm import SVC

#import metrics to compute accuracy
from sklearn.metrics import accuracy_score, f1_score, classification_report

#instantiate classifier with default hyperparameters
svc = SVC()

#import GridSearchCV
from sklearn.model_selection import GridSearchCV

#declare parameters for hyperparameter tuning
parameters = [{'C':[1, 10, 100], 'kernel':['linear']},{'C':[1, 10, 100, 1000], 'kernel':['rbf'], 'gamma':[0.1, 0.2, 0.3, 0.4]}]
grid_search = GridSearchCV(estimator=svc, param_grid=parameters, scoring='f1_weighted', cv=5, verbose=10)

grid_search.fit(X_train, t_train)

#examine the best model

#best score achieved during the GridSearchCV
print('GridSearch CV best score : {:.4f}\n\n'.format(grid_search.best_score_))

# print parameters that give the best results
print('Parameters that give the best results :','\n\n', (grid_search.best_params_))

# print estimator that was chosen by the GridSearch
print('\n\nEstimator that was chosen by the search :','\n\n', (grid_search.best_estimator_))

# calculate GridSearch CV score on test set
t_pred = grid_search.predict(X_test)

print('Model classification report with GridSearch CV: \n', classification_report(t_test, t_pred))

cm = confusion_matrix(t_test, t_pred)
cm_matrix = pd.DataFrame(data=cm, columns=['Normal', 'Suspect', 'Pathological'], index=['Normal', 'Suspect', 'Pathological'])
sea.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
plt.show()